{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TennisBrain\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.path.abspath(\"Tennis_Linux/Tennis.x86_64\")\n",
    "env = UnityEnvironment(file_name=file_path, no_graphics=True)\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "print(brain_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -6.65278625 -1.5        -0.          0.\n",
      "  6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: 0.04500000085681677\n",
      "Total score (averaged over agents) this episode: 0.04500000085681677\n",
      "[[ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.         -6.14030886 -1.5        -0.          0.\n",
      "  -7.11741829  6.         -0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.         -7.9574213  -1.5         0.          0.\n",
      "   7.11741829  6.          0.          0.        ]]\n",
      "[[-0.52742854 -0.72832315]\n",
      " [-0.34292251 -0.02658039]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):                                         # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))\n",
    "print(states)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import namedtuple, deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import MADDPG\n",
    "\n",
    "The MADDPG contains two DDPG agents for rockets. During training, each agent receives centralized observations but makes actions based on local perspective. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import MADDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent, n_episodes=7000, max_t=1000, noise_decay=0.9997):\n",
    "    \"\"\"Deterministic Critic and Actor training.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        noise_decay(float): initial noise for decay\n",
    "    \"\"\"\n",
    "    noise = 2\n",
    "    noise_reduction = noise_decay\n",
    "    scores_window = deque(maxlen=100)  \n",
    "    scores_per_episode = [] \n",
    "    average_scores_list  = []\n",
    "\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations              # get the current state\n",
    "        score = np.zeros(num_agents)\n",
    "        agent.reset()\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, noise)\n",
    "            noise *= noise_reduction\n",
    "            env_info   = env.step(action)[brain_name]   # send the action to the environment\n",
    "            next_state = env_info.vector_observations   # get the next state\n",
    "            reward     = env_info.rewards               # get the reward\n",
    "            done       = env_info.local_done            # see if episode has finished\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if any(done):\n",
    "                break\n",
    "                \n",
    "        score_max = np.max(score)\n",
    "        scores_per_episode.append(score_max)\n",
    "        scores_window.append(score_max)\n",
    "        avg_score = np.mean(scores_window)\n",
    "        average_scores_list.append(avg_score)\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.10f}'.format(i_episode,avg_score), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.10f}, Noise: {:.10f}'.format(i_episode, avg_score, noise))\n",
    "        if avg_score >=0.5:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.10f}'.format(i_episode-100, avg_score))\n",
    "            torch.save(agent.maddpg_agent[0].actor.state_dict(), 'checkpoint_0.pth')\n",
    "            torch.save(agent.maddpg_agent[1].actor.state_dict(), 'checkpoint_1.pth')\n",
    "            \n",
    "    return scores_per_episode, average_scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(scores, filename=None, rolling_window=100):\n",
    "    \"\"\"Plot scores and optional rolling mean using specified window.\"\"\"\n",
    "    plt.figure(figsize=(8.00,6.00))\n",
    "    plt.plot(scores, color='b', linestyle='-', linewidth=0.75) \n",
    "    plt.title(\"Scores\");\n",
    "    rolling_mean = pd.Series(scores).rolling(rolling_window, min_periods=1).mean()\n",
    "    plt.plot(rolling_mean, color='r', linestyle='-', linewidth=0.75)\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training MADDPG: Round I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.0010000000, Noise: 1.2874726458\n",
      "Episode 200\tAverage Score: 0.0110000002, Noise: 0.7932700785\n",
      "Episode 300\tAverage Score: 0.0010000000, Noise: 0.5155834174\n",
      "Episode 400\tAverage Score: 0.0000000000, Noise: 0.3367144346\n",
      "Episode 500\tAverage Score: 0.0000000000, Noise: 0.2198996450\n",
      "Episode 600\tAverage Score: 0.0000000000, Noise: 0.1436108729\n",
      "Episode 700\tAverage Score: 0.0105000002, Noise: 0.0886179959\n",
      "Episode 800\tAverage Score: 0.0100000001, Noise: 0.0542585922\n",
      "Episode 900\tAverage Score: 0.0050000001, Noise: 0.0342433477\n",
      "Episode 1000\tAverage Score: 0.0110000002, Noise: 0.0207597755\n",
      "Episode 1100\tAverage Score: 0.0199000003, Noise: 0.0122097843\n",
      "Episode 1200\tAverage Score: 0.0070000001, Noise: 0.0076390043\n",
      "Episode 1300\tAverage Score: 0.0190000003, Noise: 0.0043300631\n",
      "Episode 1400\tAverage Score: 0.0080000001, Noise: 0.0026156340\n",
      "Episode 1500\tAverage Score: 0.0169000003, Noise: 0.0014706730\n",
      "Episode 1600\tAverage Score: 0.0180000003, Noise: 0.0008005381\n",
      "Episode 1700\tAverage Score: 0.0230000003, Noise: 0.0004259362\n",
      "Episode 1800\tAverage Score: 0.0470000007, Noise: 0.0001985965\n",
      "Episode 1900\tAverage Score: 0.0597000009, Noise: 0.0000864746\n",
      "Episode 2000\tAverage Score: 0.0514000008, Noise: 0.0000401867\n",
      "Episode 2100\tAverage Score: 0.0437000007, Noise: 0.0000182382\n",
      "Episode 2200\tAverage Score: 0.0489000008, Noise: 0.0000082375\n",
      "Episode 2300\tAverage Score: 0.0330000005, Noise: 0.0000042648\n",
      "Episode 2400\tAverage Score: 0.0595000009, Noise: 0.0000018239\n",
      "Episode 2500\tAverage Score: 0.0650000010, Noise: 0.0000007714\n",
      "Episode 2600\tAverage Score: 0.0794000013, Noise: 0.0000002826\n",
      "Episode 2700\tAverage Score: 0.0883000013, Noise: 0.0000000965\n",
      "Episode 2800\tAverage Score: 0.1039000016, Noise: 0.0000000262\n",
      "Episode 2900\tAverage Score: 0.1818000027, Noise: 0.0000000030\n",
      "Episode 3000\tAverage Score: 0.1575000024, Noise: 0.0000000005\n",
      "Episode 3100\tAverage Score: 0.1679000025, Noise: 0.0000000001\n",
      "Episode 3200\tAverage Score: 0.1610000025, Noise: 0.0000000000\n",
      "Episode 3300\tAverage Score: 0.1991000030, Noise: 0.0000000000\n",
      "Episode 3400\tAverage Score: 0.1753000027, Noise: 0.0000000000\n",
      "Episode 3500\tAverage Score: 0.1197000019, Noise: 0.0000000000\n",
      "Episode 3600\tAverage Score: 0.0980000016, Noise: 0.0000000000\n",
      "Episode 3700\tAverage Score: 0.1212000019, Noise: 0.0000000000\n",
      "Episode 3800\tAverage Score: 0.1711000026, Noise: 0.0000000000\n",
      "Episode 3900\tAverage Score: 0.1461000022, Noise: 0.0000000000\n",
      "Episode 4000\tAverage Score: 0.1799000028, Noise: 0.0000000000\n",
      "Episode 4100\tAverage Score: 0.1812000028, Noise: 0.0000000000\n",
      "Episode 4200\tAverage Score: 0.2148000033, Noise: 0.0000000000\n",
      "Episode 4300\tAverage Score: 0.1985000031, Noise: 0.0000000000\n",
      "Episode 4400\tAverage Score: 0.1621000025, Noise: 0.0000000000\n",
      "Episode 4500\tAverage Score: 0.2866000043, Noise: 0.0000000000\n",
      "Episode 4541\tAverage Score: 0.5086000076\n",
      "Environment solved in 4441 episodes!\tAverage Score: 0.5086000076\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6095d23da0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Params:\n",
    "    \"\"\"Set up configuration here.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.__dict__.update(**{\n",
    "            'buffer_size' : int(1e4),  # replay buffer size\n",
    "            'batch_size'  : 256,       # minibatch size\n",
    "            'gamma'       : 0.99,      # discount factor\n",
    "            'tau'         : 1e-3,      # for soft update of target parameters\n",
    "            'lr'          : 1e-4,      # learning rate \n",
    "            'update_every' : 1,        # how often to update the network\n",
    "})\n",
    "        \n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "params = Params()\n",
    "\n",
    "agent = MADDPG(state_size=state_size, action_size=action_size, params=params, device=device)\n",
    "scores_all, scores_avg = train(agent, n_episodes=5000)\n",
    "\n",
    "plot_scores(scores=scores_all, rolling_window=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training MADDPG: Round II\n",
    "\n",
    "Note: the result of this section can be found in **./checkpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.0049000001, Noise: 1.2452995599\n",
      "Episode 200\tAverage Score: 0.0060000001, Noise: 0.7901818878\n",
      "Episode 300\tAverage Score: 0.0000000000, Noise: 0.5182200060\n",
      "Episode 400\tAverage Score: 0.0069000001, Noise: 0.3232509882\n",
      "Episode 500\tAverage Score: 0.0060000001, Noise: 0.2030920564\n",
      "Episode 600\tAverage Score: 0.0099000002, Noise: 0.1252844675\n",
      "Episode 700\tAverage Score: 0.0296000005, Noise: 0.0663199974\n",
      "Episode 800\tAverage Score: 0.0428000006, Noise: 0.0343565544\n",
      "Episode 900\tAverage Score: 0.0437000007, Noise: 0.0173343519\n",
      "Episode 1000\tAverage Score: 0.0188000003, Noise: 0.0102073776\n",
      "Episode 1100\tAverage Score: 0.0230000004, Noise: 0.0058522564\n",
      "Episode 1200\tAverage Score: 0.0430000008, Noise: 0.0030072542\n",
      "Episode 1300\tAverage Score: 0.0451000007, Noise: 0.0015342267\n",
      "Episode 1400\tAverage Score: 0.0533000009, Noise: 0.0007458120\n",
      "Episode 1500\tAverage Score: 0.0721000011, Noise: 0.0003179982\n",
      "Episode 1600\tAverage Score: 0.0955000014, Noise: 0.0001017150\n",
      "Episode 1700\tAverage Score: 0.1008000015, Noise: 0.0000320694\n",
      "Episode 1800\tAverage Score: 0.1314000020, Noise: 0.0000067152\n",
      "Episode 1900\tAverage Score: 0.2029000030, Noise: 0.0000005443\n",
      "Episode 2000\tAverage Score: 0.3137000047, Noise: 0.0000000125\n",
      "Episode 2100\tAverage Score: 0.4238000063, Noise: 0.0000000001\n",
      "Episode 2200\tAverage Score: 0.3337000050, Noise: 0.0000000000\n",
      "Episode 2247\tAverage Score: 0.5155000077\n",
      "Environment solved in 2147 episodes!\tAverage Score: 0.5155000077\n",
      "Episode 2248\tAverage Score: 0.5105000076\n",
      "Environment solved in 2148 episodes!\tAverage Score: 0.5105000076\n",
      "Episode 2249\tAverage Score: 0.5105000076\n",
      "Environment solved in 2149 episodes!\tAverage Score: 0.5105000076\n",
      "Episode 2250\tAverage Score: 0.5075000076\n",
      "Environment solved in 2150 episodes!\tAverage Score: 0.5075000076\n",
      "Episode 2251\tAverage Score: 0.5105000076\n",
      "Environment solved in 2151 episodes!\tAverage Score: 0.5105000076\n",
      "Episode 2252\tAverage Score: 0.5085000076\n",
      "Environment solved in 2152 episodes!\tAverage Score: 0.5085000076\n",
      "Episode 2253\tAverage Score: 0.5175000077\n",
      "Environment solved in 2153 episodes!\tAverage Score: 0.5175000077\n",
      "Episode 2256\tAverage Score: 0.5055000076\n",
      "Environment solved in 2156 episodes!\tAverage Score: 0.5055000076\n",
      "Episode 2257\tAverage Score: 0.5115000077\n",
      "Environment solved in 2157 episodes!\tAverage Score: 0.5115000077\n",
      "Episode 2258\tAverage Score: 0.5055000076\n",
      "Environment solved in 2158 episodes!\tAverage Score: 0.5055000076\n",
      "Episode 2259\tAverage Score: 0.5044000076\n",
      "Environment solved in 2159 episodes!\tAverage Score: 0.5044000076\n",
      "Episode 2260\tAverage Score: 0.5044000076\n",
      "Environment solved in 2160 episodes!\tAverage Score: 0.5044000076\n",
      "Episode 2278\tAverage Score: 0.5150000077\n",
      "Environment solved in 2178 episodes!\tAverage Score: 0.5150000077\n",
      "Episode 2279\tAverage Score: 0.5180000078\n",
      "Environment solved in 2179 episodes!\tAverage Score: 0.5180000078\n",
      "Episode 2280\tAverage Score: 0.5360000081\n",
      "Environment solved in 2180 episodes!\tAverage Score: 0.5360000081\n",
      "Episode 2281\tAverage Score: 0.5370000081\n",
      "Environment solved in 2181 episodes!\tAverage Score: 0.5370000081\n",
      "Episode 2282\tAverage Score: 0.5360000081\n",
      "Environment solved in 2182 episodes!\tAverage Score: 0.5360000081\n",
      "Episode 2283\tAverage Score: 0.5380000081\n",
      "Environment solved in 2183 episodes!\tAverage Score: 0.5380000081\n",
      "Episode 2284\tAverage Score: 0.5370000081\n",
      "Environment solved in 2184 episodes!\tAverage Score: 0.5370000081\n",
      "Episode 2285\tAverage Score: 0.5370000081\n",
      "Environment solved in 2185 episodes!\tAverage Score: 0.5370000081\n",
      "Episode 2286\tAverage Score: 0.5420000082\n",
      "Environment solved in 2186 episodes!\tAverage Score: 0.5420000082\n",
      "Episode 2287\tAverage Score: 0.5420000082\n",
      "Environment solved in 2187 episodes!\tAverage Score: 0.5420000082\n",
      "Episode 2288\tAverage Score: 0.5470000082\n",
      "Environment solved in 2188 episodes!\tAverage Score: 0.5470000082\n",
      "Episode 2289\tAverage Score: 0.5480000082\n",
      "Environment solved in 2189 episodes!\tAverage Score: 0.5480000082\n",
      "Episode 2290\tAverage Score: 0.5440000082\n",
      "Environment solved in 2190 episodes!\tAverage Score: 0.5440000082\n",
      "Episode 2291\tAverage Score: 0.5430000082\n",
      "Environment solved in 2191 episodes!\tAverage Score: 0.5430000082\n",
      "Episode 2292\tAverage Score: 0.5420000082\n",
      "Environment solved in 2192 episodes!\tAverage Score: 0.5420000082\n",
      "Episode 2293\tAverage Score: 0.5420000082\n",
      "Environment solved in 2193 episodes!\tAverage Score: 0.5420000082\n",
      "Episode 2294\tAverage Score: 0.5431000082\n",
      "Environment solved in 2194 episodes!\tAverage Score: 0.5431000082\n",
      "Episode 2295\tAverage Score: 0.5512000083\n",
      "Environment solved in 2195 episodes!\tAverage Score: 0.5512000083\n",
      "Episode 2296\tAverage Score: 0.5533000083\n",
      "Environment solved in 2196 episodes!\tAverage Score: 0.5533000083\n",
      "Episode 2297\tAverage Score: 0.5453000082\n",
      "Environment solved in 2197 episodes!\tAverage Score: 0.5453000082\n",
      "Episode 2298\tAverage Score: 0.5483000082\n",
      "Environment solved in 2198 episodes!\tAverage Score: 0.5483000082\n",
      "Episode 2299\tAverage Score: 0.5483000082\n",
      "Environment solved in 2199 episodes!\tAverage Score: 0.5483000082\n",
      "Episode 2300\tAverage Score: 0.5493000082, Noise: 0.0000000000\n",
      "\n",
      "Environment solved in 2200 episodes!\tAverage Score: 0.5493000082\n",
      "Episode 2301\tAverage Score: 0.5422000082\n",
      "Environment solved in 2201 episodes!\tAverage Score: 0.5422000082\n",
      "Episode 2302\tAverage Score: 0.5542000083\n",
      "Environment solved in 2202 episodes!\tAverage Score: 0.5542000083\n",
      "Episode 2303\tAverage Score: 0.5713000086\n",
      "Environment solved in 2203 episodes!\tAverage Score: 0.5713000086\n",
      "Episode 2304\tAverage Score: 0.5583000084\n",
      "Environment solved in 2204 episodes!\tAverage Score: 0.5583000084\n",
      "Episode 2305\tAverage Score: 0.5583000084\n",
      "Environment solved in 2205 episodes!\tAverage Score: 0.5583000084\n",
      "Episode 2306\tAverage Score: 0.5633000085\n",
      "Environment solved in 2206 episodes!\tAverage Score: 0.5633000085\n",
      "Episode 2307\tAverage Score: 0.5823000088\n",
      "Environment solved in 2207 episodes!\tAverage Score: 0.5823000088\n",
      "Episode 2308\tAverage Score: 0.5723000086\n",
      "Environment solved in 2208 episodes!\tAverage Score: 0.5723000086\n",
      "Episode 2309\tAverage Score: 0.5713000086\n",
      "Environment solved in 2209 episodes!\tAverage Score: 0.5713000086\n",
      "Episode 2310\tAverage Score: 0.5553000084\n",
      "Environment solved in 2210 episodes!\tAverage Score: 0.5553000084\n",
      "Episode 2311\tAverage Score: 0.5563000084\n",
      "Environment solved in 2211 episodes!\tAverage Score: 0.5563000084\n",
      "Episode 2312\tAverage Score: 0.5663000085\n",
      "Environment solved in 2212 episodes!\tAverage Score: 0.5663000085\n",
      "Episode 2313\tAverage Score: 0.5663000085\n",
      "Environment solved in 2213 episodes!\tAverage Score: 0.5663000085\n",
      "Episode 2314\tAverage Score: 0.5783000087\n",
      "Environment solved in 2214 episodes!\tAverage Score: 0.5783000087\n",
      "Episode 2315\tAverage Score: 0.5893000089\n",
      "Environment solved in 2215 episodes!\tAverage Score: 0.5893000089\n",
      "Episode 2316\tAverage Score: 0.5923000089\n",
      "Environment solved in 2216 episodes!\tAverage Score: 0.5923000089\n",
      "Episode 2317\tAverage Score: 0.6103000092\n",
      "Environment solved in 2217 episodes!\tAverage Score: 0.6103000092\n",
      "Episode 2318\tAverage Score: 0.6133000092\n",
      "Environment solved in 2218 episodes!\tAverage Score: 0.6133000092\n",
      "Episode 2319\tAverage Score: 0.6254000094\n",
      "Environment solved in 2219 episodes!\tAverage Score: 0.6254000094\n",
      "Episode 2320\tAverage Score: 0.6264000094\n",
      "Environment solved in 2220 episodes!\tAverage Score: 0.6264000094\n",
      "Episode 2321\tAverage Score: 0.6254000094\n",
      "Environment solved in 2221 episodes!\tAverage Score: 0.6254000094\n",
      "Episode 2322\tAverage Score: 0.6424000096\n",
      "Environment solved in 2222 episodes!\tAverage Score: 0.6424000096\n",
      "Episode 2323\tAverage Score: 0.6194000093\n",
      "Environment solved in 2223 episodes!\tAverage Score: 0.6194000093\n",
      "Episode 2324\tAverage Score: 0.6264000094\n",
      "Environment solved in 2224 episodes!\tAverage Score: 0.6264000094\n",
      "Episode 2325\tAverage Score: 0.6314000095\n",
      "Environment solved in 2225 episodes!\tAverage Score: 0.6314000095\n",
      "Episode 2326\tAverage Score: 0.6274000094\n",
      "Environment solved in 2226 episodes!\tAverage Score: 0.6274000094\n",
      "Episode 2327\tAverage Score: 0.6314000095\n",
      "Environment solved in 2227 episodes!\tAverage Score: 0.6314000095\n",
      "Episode 2328\tAverage Score: 0.6324000095\n",
      "Environment solved in 2228 episodes!\tAverage Score: 0.6324000095\n",
      "Episode 2329\tAverage Score: 0.6534000098\n",
      "Environment solved in 2229 episodes!\tAverage Score: 0.6534000098\n",
      "Episode 2330\tAverage Score: 0.6523000098\n",
      "Environment solved in 2230 episodes!\tAverage Score: 0.6523000098\n",
      "Episode 2331\tAverage Score: 0.6673000100\n",
      "Environment solved in 2231 episodes!\tAverage Score: 0.6673000100\n",
      "Episode 2332\tAverage Score: 0.6663000100\n",
      "Environment solved in 2232 episodes!\tAverage Score: 0.6663000100\n",
      "Episode 2333\tAverage Score: 0.6653000100\n",
      "Environment solved in 2233 episodes!\tAverage Score: 0.6653000100\n",
      "Episode 2334\tAverage Score: 0.6783000102\n",
      "Environment solved in 2234 episodes!\tAverage Score: 0.6783000102\n",
      "Episode 2335\tAverage Score: 0.6783000102\n",
      "Environment solved in 2235 episodes!\tAverage Score: 0.6783000102\n",
      "Episode 2336\tAverage Score: 0.6853000103\n",
      "Environment solved in 2236 episodes!\tAverage Score: 0.6853000103\n",
      "Episode 2337\tAverage Score: 0.6913000104\n",
      "Environment solved in 2237 episodes!\tAverage Score: 0.6913000104\n",
      "Episode 2338\tAverage Score: 0.6843000103\n",
      "Environment solved in 2238 episodes!\tAverage Score: 0.6843000103\n",
      "Episode 2339\tAverage Score: 0.6793000102\n",
      "Environment solved in 2239 episodes!\tAverage Score: 0.6793000102\n",
      "Episode 2340\tAverage Score: 0.6713000101\n",
      "Environment solved in 2240 episodes!\tAverage Score: 0.6713000101\n",
      "Episode 2341\tAverage Score: 0.6593000099\n",
      "Environment solved in 2241 episodes!\tAverage Score: 0.6593000099\n",
      "Episode 2342\tAverage Score: 0.6643000100\n",
      "Environment solved in 2242 episodes!\tAverage Score: 0.6643000100\n",
      "Episode 2343\tAverage Score: 0.6383000096\n",
      "Environment solved in 2243 episodes!\tAverage Score: 0.6383000096\n",
      "Episode 2344\tAverage Score: 0.6363000095\n",
      "Environment solved in 2244 episodes!\tAverage Score: 0.6363000095\n",
      "Episode 2345\tAverage Score: 0.6223000093\n",
      "Environment solved in 2245 episodes!\tAverage Score: 0.6223000093\n",
      "Episode 2346\tAverage Score: 0.6233000094\n",
      "Environment solved in 2246 episodes!\tAverage Score: 0.6233000094\n",
      "Episode 2347\tAverage Score: 0.5983000090\n",
      "Environment solved in 2247 episodes!\tAverage Score: 0.5983000090\n",
      "Episode 2348\tAverage Score: 0.6243000094\n",
      "Environment solved in 2248 episodes!\tAverage Score: 0.6243000094\n",
      "Episode 2349\tAverage Score: 0.6293000094\n",
      "Environment solved in 2249 episodes!\tAverage Score: 0.6293000094\n",
      "Episode 2350\tAverage Score: 0.6323000095\n",
      "Environment solved in 2250 episodes!\tAverage Score: 0.6323000095\n",
      "Episode 2351\tAverage Score: 0.6273000094\n",
      "Environment solved in 2251 episodes!\tAverage Score: 0.6273000094\n",
      "Episode 2352\tAverage Score: 0.6353000095\n",
      "Environment solved in 2252 episodes!\tAverage Score: 0.6353000095\n",
      "Episode 2353\tAverage Score: 0.6453000097\n",
      "Environment solved in 2253 episodes!\tAverage Score: 0.6453000097\n",
      "Episode 2354\tAverage Score: 0.6693000100\n",
      "Environment solved in 2254 episodes!\tAverage Score: 0.6693000100\n",
      "Episode 2355\tAverage Score: 0.6943000104\n",
      "Environment solved in 2255 episodes!\tAverage Score: 0.6943000104\n",
      "Episode 2356\tAverage Score: 0.7003000105\n",
      "Environment solved in 2256 episodes!\tAverage Score: 0.7003000105\n",
      "Episode 2357\tAverage Score: 0.6853000103\n",
      "Environment solved in 2257 episodes!\tAverage Score: 0.6853000103\n",
      "Episode 2358\tAverage Score: 0.6853000103\n",
      "Environment solved in 2258 episodes!\tAverage Score: 0.6853000103\n",
      "Episode 2359\tAverage Score: 0.6874000103\n",
      "Environment solved in 2259 episodes!\tAverage Score: 0.6874000103\n",
      "Episode 2360\tAverage Score: 0.7034000105\n",
      "Environment solved in 2260 episodes!\tAverage Score: 0.7034000105\n",
      "Episode 2361\tAverage Score: 0.7034000105\n",
      "Environment solved in 2261 episodes!\tAverage Score: 0.7034000105\n",
      "Episode 2362\tAverage Score: 0.7024000105\n",
      "Environment solved in 2262 episodes!\tAverage Score: 0.7024000105\n",
      "Episode 2363\tAverage Score: 0.6974000105\n",
      "Environment solved in 2263 episodes!\tAverage Score: 0.6974000105\n",
      "Episode 2364\tAverage Score: 0.6965000104\n",
      "Environment solved in 2264 episodes!\tAverage Score: 0.6965000104\n",
      "Episode 2365\tAverage Score: 0.6965000104\n",
      "Environment solved in 2265 episodes!\tAverage Score: 0.6965000104\n",
      "Episode 2366\tAverage Score: 0.7175000107\n",
      "Environment solved in 2266 episodes!\tAverage Score: 0.7175000107\n",
      "Episode 2367\tAverage Score: 0.7246000108\n",
      "Environment solved in 2267 episodes!\tAverage Score: 0.7246000108\n",
      "Episode 2368\tAverage Score: 0.7216000108\n",
      "Environment solved in 2268 episodes!\tAverage Score: 0.7216000108\n",
      "Episode 2369\tAverage Score: 0.7226000108\n",
      "Environment solved in 2269 episodes!\tAverage Score: 0.7226000108\n",
      "Episode 2370\tAverage Score: 0.7236000108\n",
      "Environment solved in 2270 episodes!\tAverage Score: 0.7236000108\n",
      "Episode 2371\tAverage Score: 0.7277000109\n",
      "Environment solved in 2271 episodes!\tAverage Score: 0.7277000109\n",
      "Episode 2372\tAverage Score: 0.7268000109\n",
      "Environment solved in 2272 episodes!\tAverage Score: 0.7268000109\n",
      "Episode 2373\tAverage Score: 0.7108000106\n",
      "Environment solved in 2273 episodes!\tAverage Score: 0.7108000106\n",
      "Episode 2374\tAverage Score: 0.7178000107\n",
      "Environment solved in 2274 episodes!\tAverage Score: 0.7178000107\n",
      "Episode 2375\tAverage Score: 0.6938000104\n",
      "Environment solved in 2275 episodes!\tAverage Score: 0.6938000104\n",
      "Episode 2376\tAverage Score: 0.7028000105\n",
      "Environment solved in 2276 episodes!\tAverage Score: 0.7028000105\n",
      "Episode 2377\tAverage Score: 0.6928000103\n",
      "Environment solved in 2277 episodes!\tAverage Score: 0.6928000103\n",
      "Episode 2378\tAverage Score: 0.6738000101\n",
      "Environment solved in 2278 episodes!\tAverage Score: 0.6738000101\n",
      "Episode 2379\tAverage Score: 0.6708000100\n",
      "Environment solved in 2279 episodes!\tAverage Score: 0.6708000100\n",
      "Episode 2380\tAverage Score: 0.6568000098\n",
      "Environment solved in 2280 episodes!\tAverage Score: 0.6568000098\n",
      "Episode 2381\tAverage Score: 0.6658000099\n",
      "Environment solved in 2281 episodes!\tAverage Score: 0.6658000099\n",
      "Episode 2382\tAverage Score: 0.6688000100\n",
      "Environment solved in 2282 episodes!\tAverage Score: 0.6688000100\n",
      "Episode 2383\tAverage Score: 0.6828000102\n",
      "Environment solved in 2283 episodes!\tAverage Score: 0.6828000102\n",
      "Episode 2384\tAverage Score: 0.7088000106\n",
      "Environment solved in 2284 episodes!\tAverage Score: 0.7088000106\n",
      "Episode 2385\tAverage Score: 0.7088000106\n",
      "Environment solved in 2285 episodes!\tAverage Score: 0.7088000106\n",
      "Episode 2386\tAverage Score: 0.7268000109\n",
      "Environment solved in 2286 episodes!\tAverage Score: 0.7268000109\n",
      "Episode 2387\tAverage Score: 0.7258000108\n",
      "Environment solved in 2287 episodes!\tAverage Score: 0.7258000108\n",
      "Episode 2388\tAverage Score: 0.7238000108\n",
      "Environment solved in 2288 episodes!\tAverage Score: 0.7238000108\n",
      "Episode 2389\tAverage Score: 0.7218000108\n",
      "Environment solved in 2289 episodes!\tAverage Score: 0.7218000108\n",
      "Episode 2390\tAverage Score: 0.7318000109\n",
      "Environment solved in 2290 episodes!\tAverage Score: 0.7318000109\n",
      "Episode 2391\tAverage Score: 0.7328000109\n",
      "Environment solved in 2291 episodes!\tAverage Score: 0.7328000109\n",
      "Episode 2392\tAverage Score: 0.7328000109\n",
      "Environment solved in 2292 episodes!\tAverage Score: 0.7328000109\n",
      "Episode 2393\tAverage Score: 0.7327000109\n",
      "Environment solved in 2293 episodes!\tAverage Score: 0.7327000109\n",
      "Episode 2394\tAverage Score: 0.7397000111\n",
      "Environment solved in 2294 episodes!\tAverage Score: 0.7397000111\n",
      "Episode 2395\tAverage Score: 0.7376000110\n",
      "Environment solved in 2295 episodes!\tAverage Score: 0.7376000110\n",
      "Episode 2396\tAverage Score: 0.7396000111\n",
      "Environment solved in 2296 episodes!\tAverage Score: 0.7396000111\n",
      "Episode 2397\tAverage Score: 0.7526000112\n",
      "Environment solved in 2297 episodes!\tAverage Score: 0.7526000112\n",
      "Episode 2398\tAverage Score: 0.7486000112\n",
      "Environment solved in 2298 episodes!\tAverage Score: 0.7486000112\n",
      "Episode 2399\tAverage Score: 0.7556000113\n",
      "Environment solved in 2299 episodes!\tAverage Score: 0.7556000113\n",
      "Episode 2400\tAverage Score: 0.7616000114, Noise: 0.0000000000\n",
      "\n",
      "Environment solved in 2300 episodes!\tAverage Score: 0.7616000114\n",
      "Episode 2401\tAverage Score: 0.7557000113\n",
      "Environment solved in 2301 episodes!\tAverage Score: 0.7557000113\n",
      "Episode 2402\tAverage Score: 0.7437000111\n",
      "Environment solved in 2302 episodes!\tAverage Score: 0.7437000111\n",
      "Episode 2403\tAverage Score: 0.7277000109\n",
      "Environment solved in 2303 episodes!\tAverage Score: 0.7277000109\n",
      "Episode 2404\tAverage Score: 0.7397000110\n",
      "Environment solved in 2304 episodes!\tAverage Score: 0.7397000110\n",
      "Episode 2405\tAverage Score: 0.7387000110\n",
      "Environment solved in 2305 episodes!\tAverage Score: 0.7387000110\n",
      "Episode 2406\tAverage Score: 0.7207000108\n",
      "Environment solved in 2306 episodes!\tAverage Score: 0.7207000108\n",
      "Episode 2407\tAverage Score: 0.7247000108\n",
      "Environment solved in 2307 episodes!\tAverage Score: 0.7247000108\n",
      "Episode 2408\tAverage Score: 0.7456000111\n",
      "Environment solved in 2308 episodes!\tAverage Score: 0.7456000111\n",
      "Episode 2409\tAverage Score: 0.7606000113\n",
      "Environment solved in 2309 episodes!\tAverage Score: 0.7606000113\n",
      "Episode 2410\tAverage Score: 0.7656000114\n",
      "Environment solved in 2310 episodes!\tAverage Score: 0.7656000114\n",
      "Episode 2411\tAverage Score: 0.7886000118\n",
      "Environment solved in 2311 episodes!\tAverage Score: 0.7886000118\n",
      "Episode 2412\tAverage Score: 0.7926000118\n",
      "Environment solved in 2312 episodes!\tAverage Score: 0.7926000118\n",
      "Episode 2413\tAverage Score: 0.8116000121\n",
      "Environment solved in 2313 episodes!\tAverage Score: 0.8116000121\n",
      "Episode 2414\tAverage Score: 0.8175000122\n",
      "Environment solved in 2314 episodes!\tAverage Score: 0.8175000122\n",
      "Episode 2415\tAverage Score: 0.8295000124\n",
      "Environment solved in 2315 episodes!\tAverage Score: 0.8295000124\n",
      "Episode 2416\tAverage Score: 0.8295000124\n",
      "Environment solved in 2316 episodes!\tAverage Score: 0.8295000124\n",
      "Episode 2417\tAverage Score: 0.8065000120\n",
      "Environment solved in 2317 episodes!\tAverage Score: 0.8065000120\n",
      "Episode 2418\tAverage Score: 0.8255000123\n",
      "Environment solved in 2318 episodes!\tAverage Score: 0.8255000123\n",
      "Episode 2419\tAverage Score: 0.8085000121\n",
      "Environment solved in 2319 episodes!\tAverage Score: 0.8085000121\n",
      "Episode 2420\tAverage Score: 0.8095000121\n",
      "Environment solved in 2320 episodes!\tAverage Score: 0.8095000121\n",
      "Episode 2421\tAverage Score: 0.8105000121\n",
      "Environment solved in 2321 episodes!\tAverage Score: 0.8105000121\n",
      "Episode 2422\tAverage Score: 0.7985000119\n",
      "Environment solved in 2322 episodes!\tAverage Score: 0.7985000119\n",
      "Episode 2423\tAverage Score: 0.8025000120\n",
      "Environment solved in 2323 episodes!\tAverage Score: 0.8025000120\n",
      "Episode 2424\tAverage Score: 0.8035000120\n",
      "Environment solved in 2324 episodes!\tAverage Score: 0.8035000120\n",
      "Episode 2425\tAverage Score: 0.8095000121\n",
      "Environment solved in 2325 episodes!\tAverage Score: 0.8095000121\n",
      "Episode 2426\tAverage Score: 0.8255000123\n",
      "Environment solved in 2326 episodes!\tAverage Score: 0.8255000123\n",
      "Episode 2427\tAverage Score: 0.8455000126\n",
      "Environment solved in 2327 episodes!\tAverage Score: 0.8455000126\n",
      "Episode 2428\tAverage Score: 0.8445000126\n",
      "Environment solved in 2328 episodes!\tAverage Score: 0.8445000126\n",
      "Episode 2429\tAverage Score: 0.8235000123\n",
      "Environment solved in 2329 episodes!\tAverage Score: 0.8235000123\n",
      "Episode 2430\tAverage Score: 0.8226000123\n",
      "Environment solved in 2330 episodes!\tAverage Score: 0.8226000123\n",
      "Episode 2431\tAverage Score: 0.7996000119\n",
      "Environment solved in 2331 episodes!\tAverage Score: 0.7996000119\n",
      "Episode 2432\tAverage Score: 0.8106000121\n",
      "Environment solved in 2332 episodes!\tAverage Score: 0.8106000121\n",
      "Episode 2433\tAverage Score: 0.8366000125\n",
      "Environment solved in 2333 episodes!\tAverage Score: 0.8366000125\n",
      "Episode 2434\tAverage Score: 0.8506000127\n",
      "Environment solved in 2334 episodes!\tAverage Score: 0.8506000127\n",
      "Episode 2435\tAverage Score: 0.8516000127\n",
      "Environment solved in 2335 episodes!\tAverage Score: 0.8516000127\n",
      "Episode 2436\tAverage Score: 0.8456000126\n",
      "Environment solved in 2336 episodes!\tAverage Score: 0.8456000126\n",
      "Episode 2437\tAverage Score: 0.8376000125\n",
      "Environment solved in 2337 episodes!\tAverage Score: 0.8376000125\n",
      "Episode 2438\tAverage Score: 0.8386000125\n",
      "Environment solved in 2338 episodes!\tAverage Score: 0.8386000125\n",
      "Episode 2439\tAverage Score: 0.8476000126\n",
      "Environment solved in 2339 episodes!\tAverage Score: 0.8476000126\n",
      "Episode 2440\tAverage Score: 0.8696000130\n",
      "Environment solved in 2340 episodes!\tAverage Score: 0.8696000130\n",
      "Episode 2441\tAverage Score: 0.8756000131\n",
      "Environment solved in 2341 episodes!\tAverage Score: 0.8756000131\n",
      "Episode 2442\tAverage Score: 0.8776000131\n",
      "Environment solved in 2342 episodes!\tAverage Score: 0.8776000131\n",
      "Episode 2443\tAverage Score: 0.8786000131\n",
      "Environment solved in 2343 episodes!\tAverage Score: 0.8786000131\n",
      "Episode 2444\tAverage Score: 0.8896000133\n",
      "Environment solved in 2344 episodes!\tAverage Score: 0.8896000133\n",
      "Episode 2445\tAverage Score: 0.8896000133\n",
      "Environment solved in 2345 episodes!\tAverage Score: 0.8896000133\n",
      "Episode 2446\tAverage Score: 0.8846000132\n",
      "Environment solved in 2346 episodes!\tAverage Score: 0.8846000132\n",
      "Episode 2447\tAverage Score: 0.8916000133\n",
      "Environment solved in 2347 episodes!\tAverage Score: 0.8916000133\n",
      "Episode 2448\tAverage Score: 0.8726000130\n",
      "Environment solved in 2348 episodes!\tAverage Score: 0.8726000130\n",
      "Episode 2449\tAverage Score: 0.8696000130\n",
      "Environment solved in 2349 episodes!\tAverage Score: 0.8696000130\n",
      "Episode 2450\tAverage Score: 0.8656000129\n",
      "Environment solved in 2350 episodes!\tAverage Score: 0.8656000129\n",
      "Episode 2451\tAverage Score: 0.8666000129\n",
      "Environment solved in 2351 episodes!\tAverage Score: 0.8666000129\n",
      "Episode 2452\tAverage Score: 0.8596000128\n",
      "Environment solved in 2352 episodes!\tAverage Score: 0.8596000128\n",
      "Episode 2453\tAverage Score: 0.8386000125\n",
      "Environment solved in 2353 episodes!\tAverage Score: 0.8386000125\n",
      "Episode 2454\tAverage Score: 0.8156000122\n",
      "Environment solved in 2354 episodes!\tAverage Score: 0.8156000122\n",
      "Episode 2455\tAverage Score: 0.7986000119\n",
      "Environment solved in 2355 episodes!\tAverage Score: 0.7986000119\n",
      "Episode 2456\tAverage Score: 0.7786000116\n",
      "Environment solved in 2356 episodes!\tAverage Score: 0.7786000116\n",
      "Episode 2457\tAverage Score: 0.7796000116\n",
      "Environment solved in 2357 episodes!\tAverage Score: 0.7796000116\n",
      "Episode 2458\tAverage Score: 0.7846000117\n",
      "Environment solved in 2358 episodes!\tAverage Score: 0.7846000117\n",
      "Episode 2459\tAverage Score: 0.7916000118\n",
      "Environment solved in 2359 episodes!\tAverage Score: 0.7916000118\n",
      "Episode 2460\tAverage Score: 0.7786000116\n",
      "Environment solved in 2360 episodes!\tAverage Score: 0.7786000116\n",
      "Episode 2461\tAverage Score: 0.7856000117\n",
      "Environment solved in 2361 episodes!\tAverage Score: 0.7856000117\n",
      "Episode 2462\tAverage Score: 0.7866000117\n",
      "Environment solved in 2362 episodes!\tAverage Score: 0.7866000117\n",
      "Episode 2463\tAverage Score: 0.8026000120\n",
      "Environment solved in 2363 episodes!\tAverage Score: 0.8026000120\n",
      "Episode 2464\tAverage Score: 0.7996000119\n",
      "Environment solved in 2364 episodes!\tAverage Score: 0.7996000119\n",
      "Episode 2465\tAverage Score: 0.8066000120\n",
      "Environment solved in 2365 episodes!\tAverage Score: 0.8066000120\n",
      "Episode 2466\tAverage Score: 0.7926000118\n",
      "Environment solved in 2366 episodes!\tAverage Score: 0.7926000118\n",
      "Episode 2467\tAverage Score: 0.8066000120\n",
      "Environment solved in 2367 episodes!\tAverage Score: 0.8066000120\n",
      "Episode 2468\tAverage Score: 0.8056000120\n",
      "Environment solved in 2368 episodes!\tAverage Score: 0.8056000120\n",
      "Episode 2469\tAverage Score: 0.8056000120\n",
      "Environment solved in 2369 episodes!\tAverage Score: 0.8056000120\n",
      "Episode 2470\tAverage Score: 0.8266000123\n",
      "Environment solved in 2370 episodes!\tAverage Score: 0.8266000123\n",
      "Episode 2471\tAverage Score: 0.8476000126\n",
      "Environment solved in 2371 episodes!\tAverage Score: 0.8476000126\n"
     ]
    }
   ],
   "source": [
    "class Params:\n",
    "    \"\"\"Set up configuration here.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.__dict__.update(**{\n",
    "            'buffer_size' : int(1e4),  # replay buffer size\n",
    "            'batch_size'  : 256,       # minibatch size\n",
    "            'gamma'       : 0.99,      # discount factor\n",
    "            'tau'         : 1e-3,      # for soft update of target parameters\n",
    "            'lr'          : 1e-4,      # learning rate \n",
    "            'update_every' : 1,        # how often to update the network\n",
    "})\n",
    "        \n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "params = Params()\n",
    "\n",
    "agent = MADDPG(state_size=state_size, action_size=action_size, params=params, device=device)\n",
    "scores_all, scores_avg = train(agent, n_episodes=7000)\n",
    "\n",
    "plot_scores(scores=scores_all, rolling_window=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conclusion\n",
    "\n",
    "1. This task can be solved without collaboration between agents.\n",
    "2. As the result, the elapsed time for solving the problem is uncertain. For example, Round I takes more than 4000 epiodes to achieve 0.5 over 100 episodes. However, Round II requires 2000 only and even reaches 0.86 within 2500 episodes.\n",
    "3. When more experiments token, sometime the agent stunts at exploitation phase, and fails to achieve the goal.\n",
    "4. The design of model is critical. So far, it's unclear how a normalization layer affects the stability of training. The other issue is the the environment introducing redundant dimentions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Future work\n",
    "\n",
    "1. Try different exploration approaches\n",
    "2. Prioritized memory buffer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
